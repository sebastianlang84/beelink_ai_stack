# ==============================================================================
# TRANSCRIPT MINER - CONFIGURATION: AI KNOWLEDGE
# Migriert auf Golden Sample Template (Stand: Dez 2025)
# ==============================================================================

# 1. API - Schnittstellenkonfiguration
# ------------------------------------------------------------------------------
api:
  youtube_api_key: ${YOUTUBE_API_KEY}
  openrouter_api_key: ${OPENROUTER_API_KEY}
  # Cookies absichtlich deaktiviert (privacy-safe); Rate-Limit-Strategie nutzen.
  youtube_cookies: null

# 2. YOUTUBE - Quellen & Download-Parameter
# ------------------------------------------------------------------------------
youtube:
  channels:
    - "@everlastai"
    
  num_videos: 5
  lookback_days: 30
  max_videos_per_channel: 5
  keywords: []
  preferred_languages: ["en", "de"]

  # Rate-Limit-Strategie (ohne Cookies)
  min_delay_s: 3.0
  jitter_s: 2.0
  max_retries: 3
  backoff_base_s: 2.0
  backoff_cap_s: 60.0
  
  proxy:
    mode: none

# 3. OUTPUT - Dateimanagement & Retention
# ------------------------------------------------------------------------------
output:
  global: /home/wasti/ai_stack_data/transcript-miner/output
  topic: ai_knowledge
  metadata: true
  retention_days: 30

# 4. LOGGING - System-Logs
# ------------------------------------------------------------------------------
logging:
  level: INFO
  file: ../logs/ai_knowledge.log
  error_log_file: ../logs/ai_knowledge_error.log
  rotation_enabled: true
  rotation_when: D
  rotation_interval: 1
  rotation_backup_count: 3

# 5. ANALYSIS (LLM) - Pro-Video Wissensextraktion (Summaries)
# ------------------------------------------------------------------------------
analysis:
  llm:
    enabled: true
    mode: per_video
    model: "google/gemini-3-flash-preview"
    per_video_concurrency: 1
    reasoning_effort: high
    # Streaming: Summaries parallel zum Transcript-Download
    stream_summaries: true
    stream_worker_concurrency: 1
    stream_queue_size: 100
    max_input_tokens: 320000
    max_output_tokens: 80000
    system_prompt: |
      You are an analyst summarizing technology/AI content from video transcripts.

      OUTPUT (STRICT MARKDOWN):
      - Output ONLY Markdown. No JSON. No code fences. No preface text.
      - Write in the SAME language as the transcript.
      - No external facts. No web browsing. Only what is in the transcript.
      - Concise, factual, no filler.

      REQUIRED STRUCTURE (always, in this exact order):
      ## Source
      ## Summary
      ## Key Points & Insights
      ## Numbers
      ## Chances
      ## Risks
      ## Unknowns

      SOURCE FORMAT (bullet list; all keys required):
      - topic: <topic>
      - video_id: <video_id>
      - url: <url>
      - title: <title>
      - channel_namespace: <channel_namespace>
      - published_at: YYYY-MM-DD HH:MM UTC (or \"unknown\")
      - fetched_at: YYYY-MM-DD HH:MM UTC (or \"unknown\")
      - info_density: low|medium|high

      RULES:
      - If you are unsure, put it under ## Unknowns (do not guess).
      - Sections must exist; if empty write exactly: - none
      - Inline quotes are allowed (optional) inside parentheses, max 200 characters, verbatim.
    user_prompt_template: |
      Create a Markdown summary for EXACTLY ONE transcript below.
      Topic: ai_knowledge

      {transcripts}

# 6. REPORT - Finale Berichterstellung (Bilingual)
# ------------------------------------------------------------------------------
report:
  llm:
    model: "openai/gpt-5.2"
    system_prompt:
      de: "Du bist ein Experte für KI-Wissen und Technologie-Trends. Erstelle einen strukturierten Bericht über die neuesten Erkenntnisse aus den analysierten Videos."
      en: "You are an expert in AI knowledge and technology trends. Create a structured report on the latest insights from the analyzed videos."
